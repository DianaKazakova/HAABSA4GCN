{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496f3270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ontology_indices(ont_rem_file, num_obs):\n",
    "    # Load the CSV file using genfromtxt\n",
    "    data = np.genfromtxt(ont_rem_file, delimiter=' ')\n",
    "    indices_backup = data # indices of data deferred to neural network backup\n",
    "    \n",
    "    full_sequence = np.arange(num_obs*3) \n",
    "    \n",
    "    # Calculate the inverse of the original array\n",
    "    indices_ont = np.setdiff1d(full_sequence, indices_backup) # indices of data predicted by ontology\n",
    "    \n",
    "    return indices_backup, indices_ont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d729a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rem_2016, ont_2016 = get_ontology_indices('data/rem2016.csv', 650)\n",
    "rem_2015, ont_2015 = get_ontology_indices('data/rem2015.csv', 597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6533af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction-truth pairs \n",
    "def get_pred(file_path):\n",
    "    with open(file_path) as f:\n",
    "        lines = f.readlines()\n",
    "        return np.array([line.split('\\t') for line in lines])[:,:2]\n",
    "    \n",
    "# Filter out examples that have already been predicted by the ontology\n",
    "def mask_predictions(pred_array, rem_array):\n",
    "    return np.array([pair for i, pair in enumerate(pred_array) if i*3 in rem_array])\n",
    "\n",
    "# Get prediction accuracy\n",
    "def get_acc(pred_array):\n",
    "    count = np.sum(pred_array[:,0] == pred_array[:,1])\n",
    "    acc = count / pred_array.shape[0]\n",
    "    return acc\n",
    "\n",
    "def print_result(acc, backup_acc, combined_acc):\n",
    "    print(f'''Neural network accuracy (full sample): {100 * acc:.2f}%\\nNeural network accuracy (as backup): {100 * backup_acc:.2f}%\\nCombined ontology and nn accuracy: {100 * combined_acc:.2f}%\\n\\n''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4919422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting eval files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f9d9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def get_eval_paths(directory_path):\n",
    "    # Get a list of all subdirectories\n",
    "    subdirectories = [subdir for subdir in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, subdir))]\n",
    "\n",
    "    file_paths = {'2015': [], '2016': []}\n",
    "\n",
    "    # Iterate through each subdirectory\n",
    "    for subdir in subdirectories:\n",
    "        year = subdir[:4]\n",
    "        # Get a list of all .txt files in the subdirectory\n",
    "        txt_files = glob.glob(os.path.join(directory_path, subdir, 'epoch_*_eval.txt'))\n",
    "        if txt_files:\n",
    "            # Extract the highest {n} value from the file names\n",
    "            n_values = [int(os.path.splitext(os.path.basename(txt_file))[0].split('_')[1]) for txt_file in txt_files]\n",
    "            highest_n = max(n_values)\n",
    "\n",
    "            # Construct the file name of the .txt file with the highest {n}\n",
    "            highest_n_file = os.path.join(directory_path, subdir, f'epoch_{highest_n}_eval.txt')\n",
    "\n",
    "            # Do something with the highest_n_file\n",
    "            file_paths[year].append(highest_n_file)\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5a64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'test_models'\n",
    "accuracyOnt2016 = 0.868159 # accuracy if the ontology is used with the backup model\n",
    "accuracyOnt2016_full = 0.783077 # accuracy if only the ontology is used\n",
    "accuracyOnt2015 = 0.827703 # accuracy if the ontology is used with the backup model\n",
    "accuracyOnt2015_full = 0.658291 # accuracy if only the ontology is used\n",
    "accuracyOnt = {'2015': 0.827703, '2016': 0.868159}\n",
    "accuracyOnt_full = {'2015': 0.658291, '2016': 0.783077} # accuracy if only the ontology is used\n",
    "\n",
    "def eval_file(f, year):\n",
    "    if year == '2015':\n",
    "        rem = rem_2015\n",
    "        num_obs = 597\n",
    "    elif year == '2016':\n",
    "        rem = rem_2016\n",
    "        num_obs = 650\n",
    "\n",
    "    num_backup_predictions = len(rem) // 3 # rem - remaining_pos_vector\n",
    "    \n",
    "    # the total number of observations -  number of remaining indexes when the prediction is implicit\n",
    "    num_ont_predictions = num_obs - num_backup_predictions \n",
    "    \n",
    "    # Get predictions\n",
    "    pred_arr = get_pred(f)\n",
    "    backup_pred_arr = mask_predictions(pred_arr, rem)\n",
    "\n",
    "    # Get accuracy\n",
    "    acc = get_acc(pred_arr)\n",
    "    backup_acc = get_acc(backup_pred_arr)\n",
    "\n",
    "    combined_acc = (num_ont_predictions * accuracyOnt[year] + num_backup_predictions * backup_acc) / num_obs\n",
    "    \n",
    "    return acc, backup_acc, combined_acc\n",
    "\n",
    "def f1_file(f):\n",
    "    pred_arr = get_pred(f)\n",
    "\n",
    "\n",
    "def eval_files_from_directory(directory):\n",
    "    for f in os.listdir(directory):\n",
    "        if f.endswith('.txt'):\n",
    "            year = f[:4]\n",
    "            if year == '2015':\n",
    "                rem = rem_2015\n",
    "                num_obs = 597\n",
    "            elif year == '2016':\n",
    "                rem = rem_2016\n",
    "                num_obs = 650\n",
    "                \n",
    "            num_backup_predictions = len(rem) // 3\n",
    "            num_ont_predictions = num_obs - num_backup_predictions\n",
    "            \n",
    "            file_path = os.path.join(directory, f)\n",
    "            \n",
    "            # Get predictions\n",
    "            pred_arr = get_pred(file_path)\n",
    "            backup_pred_arr = mask_predictions(predd_arr, rem)\n",
    "            \n",
    "            # Get accuracy\n",
    "            acc = get_acc(pred_arr)\n",
    "            backup_acc = get_acc(backup_pred_arr)\n",
    "            \n",
    "            combined_acc = (num_ont_predictions * accuracyOnt[year] + num_backup_predictions * backup_acc)\n",
    "            \n",
    "            return acc, backup_acc, combined_acc\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "383a2ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8207705192629816, 0.8239202657807309, 0.8257957922948074)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_2016_f = 'test_models/2015tri_gcn+concat_seed65_reg0.027059715881067578_drop0.2285714285714286_cdrop0.2285714285714286_lr1.1122448979591838e-05_tgcnTrue_semgcnTrue_lexgcnTrue_knogcnTrue_epochs15_adam/epoch_1_eval.txt'\n",
    "eval_file(best_2016_f, '2015')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
